━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Input: X_train, y_train, X_val, y_val, Algorithm ∈ {PSO, GWO, FA}
Output: θ_best (optimal hyperparameters), F1_best
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

1:  // Data Preparation
2:  X_train_bal, y_train_bal ← SMOTE(X_train, y_train)  
3:  // Balance classes: 50% fraud, 50% non-fraud
4:  
5:  // Objective Function
6:  function Evaluate(θ):
7:      M ← BuildMLP(θ)
8:      
9:      // Train on balanced data
10:     for epoch = 1 to MaxEpochs do
11:         Train M on (X_train_bal, y_train_bal) 
12:         val_loss ← Validate M on (X_val, y_val)
13:         if val_loss improved then
14:             F1 ← ComputeF1(M, X_val, y_val)
15:             SaveBestModel(M)
16:         end if
17:     end for
18:     
19:     return 1 - F1  // Minimize
20: end function
21: 
22: // Nature-Inspired Optimization
23: Population ← Initialize(θ_search_space)
24: for iter = 1 to MaxIterations do
25:     for each θ_i in Population do
26:         fitness_i ← Evaluate(θ_i)
27:     end for
28:     Population ← UpdateByAlgorithm(Population, fitness)
29: end for
30: 
31: return Best θ and F1

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━